\chapter{Abstract}

There has been significant progress in Machine Learning (ML) and Natural
Language Processing (NLP) in recent years due to advancements in deep neural
networks. However, one of the main criticisms of these black-box models has been
their lack of transparency and weak explainability techniques. In this
thesis, we build upon the explainability of the SoPa model proposed by
\citet{schwartz2018sopa}. The strength of the SoPa model is that it incorporates
weighted finite-state automata into its neural architecture. However, its
existing explainability techniques are both localized and indirect. To address
this limitation, we developed a modified SoPa++ model that offers globalized and
direct explanations by simplification. We found that the SoPa++ model offers a
competitive accuracy range of 97.6-98.3$\%$, effective explanations by
simplification and interesting classification explanations on the Facebook
Multilingual Task Oriented Dialog (FMTOD) data set. This improved SoPa++ model
shows that black-box explainability can be effectively achieved without an
impractical compromise in performance.

% LocalWords:  NLP interpretability explainability automata FMTOD

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End:
