\chapter{Conclusions}

\label{chapter:conclusions}

In this chapter, we summarize the key findings of this thesis. We
started off this thesis by emphasizing the importance of \ac{xai} research and
correspondingly laid out clear definitions of \ac{xai}-related concepts adapted
from \citet{arrieta2020explainable}. Through our own survey of recent literature
on explainability techniques used in \ac{nlp}, we came across several
interesting studies and drew particular inspiration from
\citet{schwartz2018sopa} who developed the novel \ac{sopa} model. While functioning
well, we found \ac{sopa}'s explainability techniques to be localized and indirect
despite its neural architecture being suited for the globalized and direct
explanations by simplification explainability technique. This inspired our main
objective to propose a modified model \ac{spp}, which could allow for
effective explanations by simplification.

The most significant changes in \ac{spp} include the utility of strict
linear-chain \ac{wfaws} over linear-chain \ac{wfas}, replacement of the \ac{mlp}
in \ac{sopa} with quantized and transparent hidden layers and the introduction of a
globalized and direct explanations by simplification post-hoc explainability
technique to simplify the black-box \ac{spp} model into a transparent \ac{re}
proxy model. With these changes, we proceed to answer our three research
questions detailed in Section \ref{section:rq}.

Regarding our first research question, we observe that \ac{spp}'s best accuracy
range on the \ac{fmtod} data set of 97.6-98.3$\%$ falls into the competitive accuracy
range of 96.6-99-5$\%$ based on other recent studies. In this respect, we
conclude that \ac{spp} offers competitive performance on the \ac{fmtod} English
language intent classification task.

Regarding our second research question, we compare the accuracy scores and
distance metrics between \ac{spp} and \ac{re} proxy model pairs and observe accuracy
differences as low as $\sim$0.1$\%$ and softmax distance norms as small as $\sim$4$\%$ for
medium and large-sized models with $\tau$-thresholds ranging from 0.50-1.00. We
therefore conclude that the explanations by simplification post-hoc
explainability technique is effective on the \ac{fmtod} English language intent
classification task given larger model sizes and $\tau$-thresholds.

Regarding our third and final research question, we identify salient \ac{tauste}
neurons which received disproportionately large relative linear weights in our
best performing small \ac{re} proxy model. Next, we analyze regular expression
samples in the \ac{re} lookup layer from the aforementioned \ac{re} proxy model
corresponding to these salient neurons. Based on an analysis of these sampled
regular expressions, we observe several interesting phenomena such as lexical
segmentation, branching transitions with tokens having similar lexical semantics
and also the presence of USA-centric inductive biases captured from the training
data.

\clearpage

With these answers to our research questions, we addressed our objective of
proposing a modified \ac{spp} model that allows for effective explanations by
simplification. Furthermore, with our competitive SoPa++ model and its simpler
RE proxy; we showed that well-performing black-box models do not have to
significantly compromise performance when undergoing explainability. However, we
did encounter several limitations to the \ac{spp} model while answering our
research questions. In the next chapter, we expound on these limitations and how
they could be addressed in future research.

% LocalWords:  explainability quantized softmax centric

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
