% import packages
\documentclass[12pt,a4paper]{article}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage[colorlinks=true,citecolor=blue,linkcolor=black,urlcolor=black]{hyperref}  
\usepackage[bottom]{footmisc}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{top=3.5cm,bottom=3.5cm}
% \renewcommand{\contentsname}{Table of Contents}

% define admin variables
\title{SoPa++: Leveraging performance and explainability from hybridized RNN, CNN and weighted finite-state neural architectures$^\dagger$\footnotetext{$^\dagger$SoPa abbreviates \textbf{So}ft \textbf{Pa}tterns; \texttt{++} indicates an expansion or improvement; working title to be fine-tuned with final evaluation}}
\author{Atreya Shankar\\
\texttt{atreya.shankar@\{uni-potsdam.de,uzh.ch\}} \\
Department of Linguistics, University of Potsdam \\
Department of Computational Linguistics, University of Zurich}
\date{\today}

\begin{document}
\maketitle
\thispagestyle{empty}
\begin{abstract}
  Recent advancements in Natural Language Processing (NLP) have been largely driven by developments in Deep Learning techniques. While powerful, these methods pose a serious limitation of being ``black-box'' or opaque. This has led to problems such as adversarial attacks and inherent biases leading to downstream ethical issues. The objective of this research is to explore white-box and grey-box machine learning methods in NLP which offer explainability, while still providing competitive performance compared to their deep learning counterparts.
\end{abstract}
\renewcommand{\baselinestretch}{0.9}\normalsize
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize
\newpage
\setcounter{page}{1}
\thispagestyle{plain}
\input{section_1}
\input{section_2}
\newpage
\addcontentsline{toc}{section}{References}
\bibliography{../bibtex}
\bibliographystyle{abbrvnat}
\end{document}

% Tasks:
% TODO improve abstract as much as possible