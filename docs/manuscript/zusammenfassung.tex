\chapter{Zusammenfassung}

Im Bereich des maschinellen Lernens (ML) und der Verarbeitung natürlicher
Sprache (NLP) hat es in den letzten Jahren aufgrund der Fortschritte bei tiefen
neuronalen Netzen erhebliche Fortschritte gegeben. Einer der Hauptkritikpunkte
an diesen Black-Box-Modellen war jedoch ihre mangelnde Transparenz und
schwache Erklärbarkeitstechniken. In dieser Arbeit bauen wir auf die
Erklärbarkeit des SoPa-Modells auf, das von Schwartz, Thomson und Smith
(\citeyear{schwartz2018sopa}) vorgeschlagen wurde. Die Stärke des SoPa-Modells
ist, dass es gewichtete endliche Zustandsautomaten in seine neuronale
Architektur einbezieht. Allerdings sind die vorhandenen Erklärungsmethoden
sowohl lokalisiert als auch indirekt. Um diese Einschränkung zu beheben,
entwickelten wir ein modifiziertes SoPa++-Modell, das durch Vereinfachung
globalisierte und direkte Erklärungen bietet. Wir fanden heraus, dass das
SoPa++-Modell einen wettbewerbsfähigen Genauigkeitsbereich von 97,6-98,3$\%$,
effektive Erklärungen durch Vereinfachung und interessante
Klassifizierungserklärungen auf dem Facebook Multilingual Task Oriented Dialog
(FMTOD) Datensatz bietet. Dieses verbesserte SoPa++-Modell zeigt, dass
Black-Box-Erklärbarkeit effektiv erreicht werden kann, ohne einen unpraktischen
Kompromiss bei der Leistung einzugehen.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End:
