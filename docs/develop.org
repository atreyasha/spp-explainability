#+STARTUP: overview
#+OPTIONS: ^:nil
#+OPTIONS: p:t

** Tasks
*** Manuscript
**** Background concepts
     DEADLINE: <2021-03-05 Fri>
***** Legacy SoPa
****** Model specifications
******* describe the native explainability used; describing the two methods offered; they will be further classified in the next subsection
****** Explainability
******* justify with previous definitions why SoPa is a black-box model
******* justify with previous definitions why model's explainability proposed corresponds to partial local explanations and feature relevance 
******* discuss if the explanations fulfil constrictive, causal links and selectiveness

**** Visualization and summary-statistics 
    DEADLINE: <2021-03-11 Thu>
***** [#A] Model runs
****** add visualizations of model runs using dedicated functions, preferably all using python libraries, or otherwise defaulting to R libraries
***** [#A] FMTOD
****** add visualisation of data statistics with different partitions, perhaps as a stacked bar chart
***** [#A] Cross-model comparisons
****** compute statistics with random-seed deviations over inter-model comparisons such as average distance, misalignment, activation frequency and other useful metrics that can elucidate on-the-ground processes
****** use error-bar plot to reflect random seed iterations for binary misalignment and softmax norm differences -> analyze relationship with tau threshold vs. performance vs. softmax/binary distances
****** visualize examples where regex and neural model align and misalign, eg. with a confusion matrix
***** [#B] SoPa++ computational graph
****** add visualization of computational graph function using tikz
***** [#C] Regex OOP
****** add visualization of regex ensemble with graphviz -> can specify which pattern to visualize and how to make large scale visualizations
****** visualize patterns as dots with internal pie charts which show magnitudes of each class; displayed as a colour with legend, will show relative importance of each binary neuron and can help us segment their purposes

**** Methodologies
***** FMTOD data set
****** provide summary statistics and explanation about the data set
****** provide a visualization on the data set and its splits
****** mention that data set was altered to keep it in good quality by removing duplicates, perhaps this can be re-tested without such processing or used as a limitation/further-work -> although results appear to show that performance metric improve when using original data set because of duplicates and overlaps between train and test sets
***** Model
****** motivate structure in terms of RNNs, CNNs and WFSA where possible 
****** add pseudocode for various segments -> would help to cement certain concepts
****** try to find literature-based justification for wildcard transition -> if not use omega symbol to differentiate from the Kleene star symbol
****** add detailed information on how hard SoPa++ model differs from SoPa related to transitions and other simplifications -> motivate them using idea of explainable simplification
****** neural SoPa++ is a black-box (non-transparent) model, regex SoPa++ is a transparent model -> need justifications from background concepts, might need significant text on this portion
****** SoPa++ uses explanation by simplification (globally) -> need justification from background concepts -> not much use of global in paper, but we can make our own arguments
****** try to link as much as possible with the background concepts for models/explainability concepts
****** add github link to repo as a footnote
***** Explainability
****** explain how we make explanations by simplification work altogether
****** hard to find hierarchies of good vs. not-good explainability, but we can argue that we tried a different explainability method, i.e. explanation by simplification with a global simplified model vs. local-explanations/feature-relevance -> also we can use the constrictive argument from the paper and others
****** make claim that SoPa++ explainability has a different explainability taxonomy from that of vanilla SoPa, but don't claim it is decisively better
****** use the three good explainability criteria to show that our technique might be better theoretically, but the real test would have to be done with a target audience's survey
****** mention that the target audience of this explainability method is domain experts, since it is still very complicated
****** link back to background concepts when we discuss bringing neural and regex model as close to each other as possible
***** Quantization/Binarization
****** explain how and why we modified STE to TauSTE
****** how does binarizing help with explainability, justify requirement for it in both training and testing
***** Training/Evaluation/Explainability-evaluation
****** provide extensive details of training setup
****** provide extensive details of evaluating neural/regex models
****** provide extensive details of evaluating explanations by simplification "metric" of neural-regex models -> which should make results clearer
****** *important:* everything shown in the "Results" section should be motivated or introduced here
***** Visualizations
****** add visualization of TauSTE function
****** produce manual computational graph using tikz, building from what was made earlier
****** add visualization of in-depth computational graph in paper for clarity -> this can be automated with PyTorch tools

**** Results
***** Report F_1 scores and performances of neural models
****** report parameter counts in scores as well
****** compare performance to that of other paper(s)
****** mention again about test partition difference due to making it unique
****** consider making test-partition not unique so this could be used to compare with other studies
***** Relationship between tau threshold vs. performance vs. softmax/binary distances 
***** Visualizations
****** show visualization of training performance timelines, think about how to keep most important information
****** show visualization of tau threshold vs. performance vs. softmax/binary distances with error bars for random seed iterations
****** show confusion matrix between regex and neural models to show alignment/misalignment, if this is necessary -> but it will show interesting class differences

**** Discussion
***** Expound on trade-off between performance and transparency by looking at differently sized models
***** Discuss relationship between tau threshold and the softmax/binary distances
***** Think about why larger regex models tend to show more misalignment from neural counterparts compared to smaller models
***** Visualizations
****** show visualizations of important patterns in a regex model -> something which is small and fits well into a page
****** show TikZ visualization of each binary neuron's relative importance for classes -> would be interesting to see how saturated these are

**** Conclusions
***** Summarize everything in manuscript
***** Address research questions

**** Further work
***** Quality of explainability
****** this is subjective and a survey from the target audience would be good to have
***** Modelling
****** extract relevant points from future programming tasks and add them here
****** extend to a finite-state transducer for seq2seq tasks
****** can map linear to decision tree to get clearer picture of possibilities
****** human intervention inside regex model to monitor/improve performance
***** Analysis
****** analyzing whether patterns can help discover possible adversarial patterns
****** for the target audience of end-users -> how can a user make use of the regex model

**** Formatting
***** Paper length
****** 20-90 pages thesis length -> try to keep ideas well-motivated yet succinct
***** Points to address towards end
****** Introduction
******* fine-tune introduction with new details from other chapters
******* update motivations from Arrieta et al. 2020 "What for" section
******* add C-like reference to explain what SoPa++ means like in i++
******* add links to chapters in thesis structure, improve formatting
****** Background concepts
******* think about providing an additional definition for "understandability" 
******* include a section on risks on large NLP models and why explainability is necessary with different study
******* if possible, try to reduce references to Arrieta et al. 2020 to reduce perceived over-dependence
****** Bibliography
******* improve capitalization with braces in bibtex file
******* if possible, try to find non-arxiv citations for papers
******* remove red link color in table of contents
******* fine-tune citation color to be consistent with other colors
******* think about citing Arrieta et al. 2020 in each definition, or perhaps it is overkill
******* look into oracel/proxy names and if these can be improved
****** Manuscript admin
******* think about whether to include borrowed figures or make own -> check if permission is necessary
******* fine tune WFSA to mean either automata or automaton
******* remove sub-enumeration for single remarks under a definition 
******* add links to different sections later on once structure and content is clear
******* sort out all abbreviations and standardize formatting in terms of where they are first declared
******* change to two sided format before printing, as this works well for binding/printing
******* add Uni-Potsdam originality declaration, or modify current one to fit
******* add remaining features by referring to master template such as abstract (short summarized introduction), list of tables/figures/abbreviations, appendices, and all others
******* perform spell-check of everything at the end
       
*** Current Programming
**** Dependencies, typing and testing
***** if using R, document R dependencies such as package versions neatly (avoid =renv=)
***** include basic test code by instantiating class and/or other simple methods
***** add mypy as an explicit part of testing the source code
***** replace Union + None types with Optional type for conciseness
***** look into cases where List was replaced by Sequential and how this can be changed or understood to keep consistency (ie. keep everything to List with overloads)
**** Documentation and clean-code
***** find better naming for mimic/oracle models which is based on research terminology -> right now mix of neural and regex is being used; it would be good to have something more firm
***** GPU/CPU runs not always reproducible depending on multi-threading, see: https://pytorch.org/docs/stable/notes/randomness.html#reproducibility
***** reduce source code lines, chunking and comments -> pretty sort python code and function/class orders perhaps by length
***** add a comment above each code chunk which explains inner mechanisms better
***** update metadata eg. with comprehensive python/shell help scripts, comments describing functionality and readme descriptions for git hooks
***** add information on best model downloads and preparation -> add these to Google Drive later on
***** add pydocstrings to all functions and improve argparse documentation
***** provide description of data structures (eg. data, labels) required for training processes and lowercasing
***** update/remove git hooks depending on which features are finally used, eg. remove pre-push hook
***** test download and all other scripts to ensure they work

*** Future programming
**** Modelling improvements
***** check if packed sequences could be incoporated into model
****** might increase efficiency related to batch latency
***** find single-threaded ways to speed up regular expression searches -> bottleneck appears to be search method
****** multiprocessing with specific chunksize seems to have some effect
****** might need to have a very large batch size to see any improvements with multiprocessing
****** database with indexing could help improve regex lookup speed
***** consider using finditer for regex lookup with trace, since we should return all matches
****** make activating text unique in case we return multiple texts and not one -> but then won't correspond to activating regexes
****** might not make a huge difference since we use short sentences
****** might be better for speed reasons to leave it as a search method
***** add predict function for both mimic and oracle model which does not need extra data to be loaded -> can also accept stdin as unix pipe
**** Explore activation generalization methods
***** improve baseline simplification and rational compression method
****** handle *UNK* tokens on new data for either in regex OOP or during simplification/compression -> perhaps look for best possible match given context -> *might be well-enough handled by wildcards*
****** EITHER needs more features from simplification such as nearest neighbours OR generate them with access to the model again -> use comparison scripts to determine which improvements are necessary -> this should go into the SoPa++ neural model below trace functions -> look into legacy code for some hints -> *might be well enough handled by looking into enough training samples
***** think of taking tokens in a regex group and finding their *K-nearest-neighbours* in transition space to expand on them if possible -> only do this if there are few samples and if their neighbours have very close scores (within eps), see: https://discuss.pytorch.org/t/k-nearest-neighbor-in-pytorch/59695/2
****** would require extra neural class function to compute all transition matrices
****** hard to justify these as compression techniques, more closer to simplificiation -> but perhaps this is just a technicality which can be addressed later on
****** might not help too much since regex model appears over-activated at the binary layer compared to the neural model -> these compression generalizations will just increase activations; where we would rather expect sparsity instead
***** think of semantic clustering with digits or time or other means -> if there are no wildcards present -> would require external ontology such as WordNet -> would be slightly more work intensive and is perhaps better to leave this for further work

** Notes
*** Manuscript
**** SoPa++
***** extensions
****** leverage dynamic sub-word-level embeddings from recent advancements in Transformer-based language modeling.
****** modify the architecture and hyperparameters to use more wildcards or self-loops, and verify the usefulness of these in the mimic WFSA models.
****** modify the output multi-layer perceptron layer to a general additive layer, such as a linear regression layer, with various basis functions. This would allow for easier interpretation of the importance of patterns without the use of occlusion -> perhaps consider adding soft logic functions which could emulate negation/inclusion of rules, or possibly a soft decision tree at the top layer
****** test SoPa++ on multi-class text classification tasks
**** SoPa
***** goods: practical new architecture which maps to RNN-CNN mix via WFSAs, decent code quality in PyTorch (still functional), contact made with author and could get advice for possible extensions
***** limitations
****** SoPa utilizes static word-level token embeddings which might contribute to less dynamic learning and more overfitting towards particular tokens
****** SoPa encourages minimal learning of wildcards/self-loops and $\epsilon$-transitions, which leads to increased overfitting on rare words such as proper nouns
****** while SoPa provides an interpretable architecture to learn discrete word-level patterns, it is also utilizes occlusion to determine the importance of various patterns. Occlusion is usually a technique reserved for uninterpretable model architectures and contributes little to global explainability
****** SoPa was only tested empirically on binary text classification tasks
***** general: likely higher performance due to direct inference and less costly conversion methods  
**** Data sets
***** NLU data sets -> single sequence intent classification, typically many classes involved -> eg. ATIS, Snips, AskUbuntuCorpus, FB task oriented dataset (mostly intent classifications)
***** SOTA scores for NLU can be found on https://github.com/nghuyong/rasa-nlu-benchmark#result
***** vary training data sizes from 10% to 70% for perspective on data settings
**** Extension to new data sets
***** could extend workflow to ATIS and/or SNIPS since all other code is established
**** Constraints
***** work with RNNs only
***** seq2cls tasks -> eg. NLU/NLI/semantic tasks, try to work with simpler single (vs. double) sequence classification task
***** base main ideas off peer-reviewed artics

*** Admin
**** Research questions
***** To what extent does SoPa++ contribute to competitive performance on NLU tasks?
***** To what extent does SoPa++ contribute to explainability by simplification?
***** What interesting and relevant explanations does SoPa++ provide on NLU task(s)?
**** Timeline
***** +Initial thesis document: *15.09.2020*+
***** +Topic proposal draft: *06.11.2020*+
***** +Topic proposal final: *15.11.2020*+
***** +Topic registration: *01.02.2021*+
***** Manuscript draft submission: *31.03.2021* 
***** Offical manuscript submission: *10.04.2021*

** Legacy
*** Interpretable RNN architectures
**** State-regularized-RNNs (SR-RNNs)
***** good: very powerful and easily interpretable architecture with extensions to NLP and CV
***** good: simple code which can probably be ported to PyTorch relatively quickly
***** good: contact made with author and could get advice for possible extensions
***** problematic: code is outdated and written in Theano, TensorFlow version likely to be out by end of year
***** problematic: DFA extraction from SR-RNNs is clear, but DPDA extraction/visualization from SR-LSTMs is not clear probably because of no analog for discrete stack symbols from continuous cell (memory) states
***** possible extensions: port state-regularized RNNs to PyTorch (might be simple since code-base is generally simple), final conversion to REs for interpretability, global explainability for natural language, adding different loss to ensure words cluster to same centroid as much as possible -> or construct large automata, perhaps pursue sentiment analysis from SR-RNNs perspective instead and derive DFAs to model these
**** Rational recurences (RRNNs)
***** good: code quality in PyTorch, succinct and short
***** good: heavy mathematical background which could lend to more interesting mathematical analyses
***** problematic: seemingly missing interpretability section in paper -> theoretical and mathematical, which is good for understanding
***** problematic: hard to draw exact connection to interpretability, might take too long to understand everything
**** Finite-automation-RNNs (FA-RNNs)
***** source code likely released by November, but still requires initial REs which may not be present -> might not be the best fit
***** FA-RNNs involving REs and substitutions could be useful extensions as finite state transducers for interpretable neural machine translation

*** Interpretable surrogate extraction
***** overall more costly and less chance of high performance       
***** FSA/WFSA extraction
****** spectral learning, clustering
****** less direct interpretability
****** more proof of performance needed -> need to show it is better than simple data learning

*** Neuro-symbolic paradigms
***** research questions
****** can we train use a neuro-symbolic paradigm to attain high performance (similar to NNs) for NLP task(s)?
****** if so, can this paradigm provide us with greater explainability about the inner workings of the model?

*** Neural decision trees
***** decision trees are the same as logic programs -> the objective should be to learn logic programs
***** hierarchies are constructed in weight-space which lends itself to non-sequential models very well -> but problematic for token-level hierarchies
***** research questions
****** can we achieve similar high performance using decision tree distillation techniques (by imitating NNs)?
****** can this decision tree improve interpretability/explainability?
****** can this decision tree distillation technique outperform simple decision tree learning from training data?

*** Inductive logic on NLP search spaces
***** can potentially use existing IM models such as paraphrase detector for introspection purposes in thesis
***** n-gram power sets to explore for statistical artefacts -> ANNs can only access the search space of N-gram power sets -> solution to NLP tasks must be a statistical solution within the power sets which links back to symbolism
***** eg. differentiable ILP from DeepMind
***** propositional logic only contains atoms while predicate/first-order logic contain variables      
