#+STARTUP: overview

** Tasks
*** Research
**** Clean-code and documentation
***** TODO start populating repository with hooks, data downloads, documentation and models
***** populate manuscript and repository with key research questions which can be answered

**** Interpretable neural architectures
***** TODO explore below frameworks (by preference) and find most feasible one
***** SoPA and rational recurrences
****** first is a practical approach while second is highly theoretical
****** provide interpretable architectures which need to be further explored
****** both implementations have decent code quality
***** State-regularized-RNNs
****** practical and offers direct interpretability from architecture
****** code is outdated and written in Theano, TensorFlow version likely to be out by end of year*
****** possible work: port state-regularized RNNs to PyTorch with CUDA headers
****** final conversion to REs for interpretability
***** Finite-automation-RNNs
****** source code likely released by November, but still requires initial REs which may not be present
****** FA-RNNs involving REs and substitutions could be useful extensions as finite state transducers for interpretable neural machine translation
***** **GIST:** likely higher performance due to direct inference and less costly

**** Data sets
***** TODO search for popular NLU datasets which have existing RNN models as (almost) SOTAs
***** TODO read more into these tasks and find one that has potential for interpretability -> likely reduce task to binary case for easier processing (eg. entailment)
 
**** Interpretable surrogate extraction
***** FSA/WFSA extraction
****** spectral learning, clustering
****** less direct interpretability
****** more proof of performance needed -> need to show it is better than simple data learning
***** **GIST:** more costly and less chance of high performance       

**** Constraints
***** work with RNNs only
***** seq2cls tasks -> eg. NLU/semantic, paraphrase detection
***** base main ideas off peer-reviewed articles 

**** High-level
***** **globally explainable** -> exposes inner mechanisms and global biases which could help for ethical and adversarial problem detections
***** **high-performance** -> competitive with similar non-explainable learnint techniques
***** **contributions** -> should add insights which are new and not commonly found in research so far

*** Admin
***** +Initial thesis document: 15.09.20+
***** Topic proposal draft: 06.11.20
***** Topic proposal final: 15.11.20
***** Topic registration: 01.02.20  
***** Manuscript submission: 18.03.20, try to extend if possible  
***** **Note:** meeting every 3 weeks with Sharid and more regularly with Mathias 

*** Manuscript notes
***** FSA/WFAs -> input theoretical CS, mathematics background to describe these
***** ann's historical literature -> describe how ANNs approximate symbolic representations
***** extension/recommendations -> transducer for seq2seq tasks

** Completed
***** DONE add org-mode hook to remove startup visibility headers in org-mode to markdown conversion
      CLOSED: [2020-10-22 Thu 13:28]
***** DONE Set up repo, manuscript and develop log
      CLOSED: [2020-10-22 Thu 12:36]
      
** Legacy
*** Neuro-symbolic paradigms
***** research questions:
****** can we train use a neuro-symbolic paradigm to attain high performance (similar to NNs) for NLP task(s)?
****** if so, can this paradigm provide us with greater explainability about the inner workings of the model?

*** Neural decision trees
***** decision trees are the same as logic programs -> the objective should be to learn logic programs
***** hierarchies are constructed in weight-space which lends itself to non-sequential models very well -> but problematic for token-level hierarchies
***** research questions:
****** can we achieve similar high performance using decision tree distillation techniques (by imitating NNs)?
****** can this decision tree improve interpretability/explainability?
****** can this decision tree distillation technique outperform simple decision tree learning from training data?

*** Inductive logic on NLP search spaces
***** can potentially use existing IM models such as paraphrase detector for introspection purposes in thesis
***** n-gram power sets to explore for statistical artefacts -> ANNs can only access the search space of N-gram power sets -> solution to NLP tasks must be a statistical solution within the power sets which links back to symbolism
***** eg. differentiable ILP from DeepMind
***** propositional logic only contains atoms while predicate/first-order logic contain variables
