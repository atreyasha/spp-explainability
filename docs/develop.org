#+STARTUP: overview
#+OPTIONS: ^:nil
#+OPTIONS: p:t

** Notes
*** Tasks
**** Slides (aim to write two per day)
***** TODO Background concepts (~4 slides)
****** SoPa and its explainability techniques -> mention localized and indirect
******* talk about WFA's directly here 
******* think of using different figure than SoPa computational graph in first figure 
***** TODO Data set and methodologies (~6 slides)
****** SoPa++
******* talk about STE's directly here
***** Results (~3 slides)
***** Discussion (~3 slides)
***** Conclusions (~1 slide)
***** Future work (~2 slide)
**** Do spell-check of all slides 
**** Complete animations of slides
**** Do timed practice to hit 20 minutes
**** Prepare for counter-questions for additional 30 minutes

*** Admin
**** Timeline
***** +Initial thesis document: *15.09.2020*+
***** +Topic proposal draft: *06.11.2020*+
***** +Topic proposal final: *15.11.2020*+
***** +Topic registration: *01.02.2021*+
***** +Offical manuscript submission: *12.04.2021*+
***** Thesis defense: *08.07.2021*

** Legacy
*** Interpretable RNN architectures
**** State-regularized-RNNs (SR-RNNs)
***** good: very powerful and easily interpretable architecture with extensions to NLP and CV
***** good: simple code which can probably be ported to PyTorch relatively quickly
***** good: contact made with author and could get advice for possible extensions
***** problematic: code is outdated and written in Theano, TensorFlow version likely to be out by end of year
***** problematic: DFA extraction from SR-RNNs is clear, but DPDA extraction/visualization from SR-LSTMs is not clear probably because of no analog for discrete stack symbols from continuous cell (memory) states
***** possible extensions: port state-regularized RNNs to PyTorch (might be simple since code-base is generally simple), final conversion to REs for interpretability, global explainability for natural language, adding different loss to ensure words cluster to same centroid as much as possible -> or construct large automata, perhaps pursue sentiment analysis from SR-RNNs perspective instead and derive DFAs to model these
**** Rational recurences (RRNNs)
***** good: code quality in PyTorch, succinct and short
***** good: heavy mathematical background which could lend to more interesting mathematical analyses
***** problematic: seemingly missing interpretability section in paper -> theoretical and mathematical, which is good for understanding
***** problematic: hard to draw exact connection to interpretability, might take too long to understand everything
**** Finite-automation-RNNs (FA-RNNs)
***** source code likely released by November, but still requires initial REs which may not be present -> might not be the best fit
***** FA-RNNs involving REs and substitutions could be useful extensions as finite state transducers for interpretable neural machine translation
*** Interpretable surrogate extraction
***** overall more costly and less chance of high performance       
***** FA/WFA extraction
****** spectral learning, clustering
****** less direct interpretability
****** more proof of performance needed -> need to show it is better than simple data learning
*** Neuro-symbolic paradigms
***** research questions
****** can we train use a neuro-symbolic paradigm to attain high performance (similar to NNs) for NLP task(s)?
****** if so, can this paradigm provide us with greater explainability about the inner workings of the model?
*** Neural decision trees
***** decision trees are the same as logic programs -> the objective should be to learn logic programs
***** hierarchies are constructed in weight-space which lends itself to non-sequential models very well -> but problematic for token-level hierarchies
***** research questions
****** can we achieve similar high performance using decision tree distillation techniques (by imitating NNs)?
****** can this decision tree improve interpretability/explainability?
****** can this decision tree distillation technique outperform simple decision tree learning from training data?
*** Inductive logic on NLP search spaces
***** can potentially use existing IM models such as paraphrase detector for introspection purposes in thesis
***** n-gram power sets to explore for statistical artefacts -> ANNs can only access the search space of N-gram power sets -> solution to NLP tasks must be a statistical solution within the power sets which links back to symbolism
***** eg. differentiable ILP from DeepMind
***** propositional logic only contains atoms while predicate/first-order logic contain variables      
