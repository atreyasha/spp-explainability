% import packages
\documentclass[8pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hhline}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage[export]{adjustbox}
\usepackage[justification=centering]{caption}
\usepackage[backend=bibtex,style=authoryear,maxcitenames=2,natbib=true,maxbibnames=99]{biblatex}

% set beamer parameters
\usetheme{Frankfurt}
\usecolortheme{default}
\setbeamerfont{footnote}{size=\Tiny}
\setbeamertemplate{page number in head/foot}{}
\setbeamertemplate{bibliography item}{}
\setbeamertemplate{caption}[numbered]
\setbeamercovered{transparent}
\setbeamerfont{institute}{size=\small}
\addtobeamertemplate{navigation symbols}{}{%
  \usebeamerfont{footline}%
  \usebeamercolor[fg]{footline}%
  \hspace{2em}%
  \raisebox{1.7pt}[0pt][0pt]{\insertframenumber/\inserttotalframenumber}
}
\setbeamertemplate{enumerate items}[square]
\setbeamertemplate{section in toc}[square]

% special command to uncover graphics
% source: https://tex.stackexchange.com/a/415335
\newcommand<>{\uncovergraphics}[2][{}]{
  % Taken from: <https://tex.stackexchange.com/a/354033/95423>
  \begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (B) at (4,0)
    {\includegraphics[#1]{#2}}; \alt#3{}{%
      \fill [draw=none, fill=white, fill opacity=0.7] (B.north west) -- (B.north
      east) -- (B.south east) -- (B.south west) -- (B.north west) -- cycle; }
  \end{tikzpicture}
}

% set caption parameters
\DeclareCaptionFormat{myformat}{\fontsize{6}{6}\selectfont#1#2#3}
\captionsetup{format=myformat}
\captionsetup[figure]{labelfont={bf},name={Figure}}
\captionsetup[table]{labelfont={bf},name={Table}}

% set bibliography parameters
\renewcommand\refname{Bibliography}
\addbibresource{../bibtex.bib}
\setlength\bibitemsep{1.5\itemsep}
\let\oldcitep=\citep
\renewcommand\citep[1]{{\textcolor{blue}{\oldcitep{#1}}}}
\let\oldcitet=\citet
\renewcommand\citet[1]{{\textcolor{blue}{\oldcitet{#1}}}}

% miscellaneous settings
\settowidth{\leftmargini}{\usebeamertemplate{itemize item}}
\addtolength{\leftmargini}{\labelsep}
\renewcommand{\arraystretch}{1.3}
\graphicspath{{../visuals/}}

% set admin details
\title{SoPa++: Leveraging explainability from hybridized RNN, CNN and weighted
  finite-state neural architectures}
\subtitle{M.Sc. Thesis Defense}
\author{Atreya Shankar (799227), \texttt{shankar.atreya@gmail.com} \\ Cognitive Systems:
  Language, Learning, and Reasoning (M.Sc.) \\ 1\textsuperscript{st} Supervisor: Dr. Sharid
  Loáiciga, University of Potsdam \\ 2\textsuperscript{nd}
  Supervisor: Mathias Müller, M.A., University of Zurich}
\institute{Foundations of Computational Linguistics \\ Department of Linguistics \\ University of Potsdam, SoSe 2021}
\date{July 8, 2021}

% start presentation
\begin{document}
\begin{frame}
  \maketitle
\end{frame}

\begin{frame}
  \frametitle{Overview}
  \tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}
  \frametitle{Motivation}

  \begin{columns}[T]
    \begin{column}{.40\textwidth}
      \begin{itemize}
        \setlength\itemsep{1em}
        \uncover<1>{
          \item Trend of increasingly complex deep learning models achieving
          SOTA performance on ML and NLP tasks (Figure \ref{fig:nlp_progress})
          \item To address emerging concerns such as inductive biases, several
          studies make argument for research into XAI; for example
          \citet{danilevsky2020survey} and \citet{arrieta2020explainable}}
        \uncover<2>{
          \item \citet{schwartz2018sopa} approach XAI in NLP by proposing
          an explainable hybridized neural architecture called
          \textbf{So}ft \textbf{Pa}tterns (SoPa; Figure \ref{fig:sopa})
          \item SoPa provides localized and indirect explainability despite being suited for
          \textbf{globalized and direct} explanations by simplification
        } 
      \end{itemize}
    \end{column}
    \hfill
    \begin{column}{.60\textwidth}
        \centering
        \uncovergraphics<1>[width=6cm, valign=t]{pdfs/borrowed/nlp_sota_model_size_progress.pdf}
        \uncover<1>{\captionof{figure}{Parameter counts of recently released pre-trained language
            models; figure taken from \citet{sanh2019distilbert}}}
        \label{fig:nlp_progress}
        \vspace{5pt}
        \uncovergraphics<2>[width=6cm, valign=t]{pdfs/borrowed/sopa_computational_graph.pdf}
        \uncover<2>{\captionof{figure}{SoPa's partial computational graph; figure taken from
            \citet{schwartz2018sopa}}}
        \label{fig:sopa}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Objective and research questions}

  \uncover<1->{ Objective: \setlength{\leftmargini}{0.5cm}
    \begin{itemize}
      \item Address limitations of SoPa by proposing \textbf{SoPa++}, which
      could allow for effective explanations by simplification.
    \end{itemize}
  }
  
  \vspace{10pt}

  \uncover<2->{ Process:
    \begin{itemize}
      \item We study the performance and explanations by simplification of
      SoPa++ on the \textbf{FMTOD} data set from
      \citet{schuster-etal-2019-cross-lingual}; focusing on the English-language
      intent classification task.
    \end{itemize}
  }
  
  \vspace{10pt}

  \uncover<3->{ Research questions:
    \begin{enumerate}
      \setlength\itemsep{1em}
      \item Does SoPa++ provide \textbf{competitive} performance?
      \item To what extent does SoPa++ contribute to \textbf{effective}
      explanations by simplification?
      \item What \textbf{interesting and relevant} explanations can SoPa++
      provide?
    \end{enumerate}
  }
\end{frame}

% macro for showing TOC on each new section
\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Progress}
    \tableofcontents[currentsection]
  \end{frame}
}

\section{Background concepts}

\begin{frame}
  \frametitle{Explainability}
  \begin{columns}[T]
    \begin{column}{.40\textwidth}
      \begin{itemize}
        \setlength\itemsep{1em}
        \uncover<1>{
          \item Transparency is a passive feature that a model exhibits
          \item Explainability is an active feature that involves target
          audiences (Figure \ref{fig:xai_target_audience})
          \item \citet{arrieta2020explainable} explore a taxonomy of explainability techniques 
        }
        \uncover<2>{
          \item Prominent explainability techniques include local explanations, feature
          relevance and \textbf{explanations by simplification}
          \item Explainability techniques can provide meaningful insights into
          decision boundaries within black-box models (Figure \ref{fig:lime_husky})
        } 
      \end{itemize}
    \end{column}
    \hfill
    \begin{column}{.60\textwidth}
        \centering
        \uncovergraphics<1>[width=6.2cm,trim={0.3cm 0.3cm 0.5cm
          0.3cm},clip,valign=t]{pdfs/borrowed/xai_target_audience.pdf}
        \uncover<1>{\captionof{figure}{Examples of various target audiences in XAI; figure taken from
            \citet{arrieta2020explainable}}}
        \label{fig:xai_target_audience}
        \vspace{5pt}
        \uncovergraphics<2>[width=6cm,trim={0.1cm 0.1cm 0.1cm
          0.1cm},clip,valign=t]{pdfs/borrowed/lime_husky.pdf}
        \uncover<2>{\captionof{figure}{Local explanation for ``Wolf''
            classification decision, figure taken from \citet{lime}}}
        \label{fig:lime_husky}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Soft Patterns (SoPa)}

\end{frame}

\section{Data and methodologies}
\section{Results}
\section{Discussion}
\section{Conclusions}
\section{Future work}

\begin{frame}[allowframebreaks]
  \frametitle{Bibliography} \printbibliography[title = {Bibliography}]
\end{frame}

\end{document}
