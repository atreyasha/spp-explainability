@article{doran2017does,
  author    = {Derek Doran and
               Sarah Schulz and
               Tarek R. Besold},
  title     = {What Does Explainable {AI} Really Mean? {A} New Conceptualization
               of Perspectives},
  journal   = {CoRR},
  volume    = {abs/1710.00794},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.00794},
  archivePrefix = {arXiv},
  eprint    = {1710.00794},
  timestamp = {Mon, 13 Aug 2018 16:48:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-00794.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{arrieta2020explainable,
  title={Explainable Artificial Intelligence ({XAI}): Concepts, taxonomies, opportunities and challenges toward responsible {AI}},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information Fusion},
  volume={58},
  pages={82--115},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@article{wan2020nbdt,
  title={NBDT: Neural-Backed Decision Trees},
  author={Wan, Alvin and Dunlap, Lisa and Ho, Daniel and Yin, Jihan and Lee, Scott and Jin, Henry and Petryk, Suzanne and Bargal, Sarah Adel and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2004.00221},
  year={2020}
}

@article{li2018generalize,
  title={Generalize symbolic knowledge with neural rule engine},
  author={Li, Shen and Xu, Hengru and Lu, Zhengdong},
  journal={arXiv preprint arXiv:1808.10326},
  year={2018}
}

@inproceedings{kepner2018sparse,
  title={Sparse deep neural network exact solutions},
  author={Kepner, Jeremy and Gadepally, Vikalo and Jananthan, Hayden and Milechin, Lauren and Samsi, Sid},
  booktitle={2018 IEEE High Performance extreme Computing Conference (HPEC)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}

@article{hou2018learning,
  author    = {Bo{-}Jian Hou and
               Zhi{-}Hua Zhou},
  title     = {Learning with Interpretable Structure from {RNN}},
  journal   = {CoRR},
  volume    = {abs/1810.10708},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.10708},
  archivePrefix = {arXiv},
  eprint    = {1810.10708},
  timestamp = {Wed, 31 Oct 2018 14:24:29 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-10708.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{law2015ilasp,
  title={The ILASP system for learning answer set programs},
  author={Law, Mark and Russo, Alessandra and Broda, Krysia},
  year={2015}
}

@article{DBLP:journals/corr/abs-1906-03523,
  author    = {Ali Payani and
               Faramarz Fekri},
  title     = {Inductive Logic Programming via Differentiable Deep Neural Logic Networks},
  journal   = {CoRR},
  volume    = {abs/1906.03523},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.03523},
  archivePrefix = {arXiv},
  eprint    = {1906.03523},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-03523.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{evans2018learning,
  title={Learning explanatory rules from noisy data},
  author={Evans, Richard and Grefenstette, Edward},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={1--64},
  year={2018}
}

@inproceedings{schwartz2018sopa,
    title = "Bridging {CNN}s, {RNN}s, and Weighted Finite-State Machines",
    author = "Schwartz, Roy  and
      Thomson, Sam  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1028",
    doi = "10.18653/v1/P18-1028",
    pages = "295--305",
    abstract = "Recurrent and convolutional neural networks comprise two distinct families of models that have proven to be useful for encoding natural language utterances. In this paper we present SoPa, a new model that aims to bridge these two approaches. SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns. We show that SoPa is an extension of a one-layer CNN, and that such CNNs are equivalent to a restricted version of SoPa, and accordingly, to a restricted form of WFSA. Empirically, on three text classification tasks, SoPa is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline, and is particularly useful in small data settings.",
}

@InProceedings{wang2019state, title = {State-Regularized Recurrent Neural Networks}, author = {Wang, Cheng and Niepert, Mathias}, pages = {6596--6606}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, address = {Long Beach, California, USA}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/wang19j/wang19j.pdf}, url = {http://proceedings.mlr.press/v97/wang19j.html}, abstract = {Recurrent neural networks are a widely used class of neural architectures with two shortcomings. First, it is difficult to understand what exactly they learn. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in principle. We aim to address both shortcomings with a class of recurrent networks that use a stochastic state transition mechanism between cell applications. This mechanism, which we term state-regularization, makes RNNs transition between a finite set of learnable states. We evaluate state-regularized RNNs on (1) regular languages for the purpose of automata extraction; (2) nonregular languages such as balanced parentheses, palindromes, and the copy task where external memory is required; and (3) real-word sequence learning tasks for sentiment analysis, visual object recognition, and language modeling. We show that state-regularization simplifies the extraction of finite state automata from the RNNâ€™s state transition dynamics; forces RNNs to operate more like automata with external memory and less like finite state machines; and makes RNNs more interpretable.} }

@inproceedings{peng2018rational,
    title = "Rational Recurrences",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Thomson, Sam  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1152",
    doi = "10.18653/v1/D18-1152",
    pages = "1203--1214",
    abstract = "Despite the tremendous empirical success of neural models in natural language processing, many of them lack the strong intuitions that accompany classical machine learning approaches. Recently, connections have been shown between convolutional neural networks (CNNs) and weighted finite state automata (WFSAs), leading to new interpretations and insights. In this work, we show that some recurrent neural networks also share this connection to WFSAs. We characterize this connection formally, defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs. We show that several recent neural models use rational recurrences. Our analysis provides a fresh view of these models and facilitates devising new neural architectures that draw inspiration from WFSAs. We present one such model, which performs better than two recent baselines on language modeling and text classification. Our results demonstrate that transferring intuitions from classical models like WFSAs can be an effective approach to designing and understanding neural models.",
}

@article{DBLP:journals/corr/abs-1905-08701,
  author    = {Ananda Theertha Suresh and
               Brian Roark and
               Michael Riley and
               Vlad Schogol},
  title     = {Approximating probabilistic models as weighted finite automata},
  journal   = {CoRR},
  volume    = {abs/1905.08701},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.08701},
  archivePrefix = {arXiv},
  eprint    = {1905.08701},
  timestamp = {Wed, 29 May 2019 11:27:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-08701.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators.},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert and others},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@article{bocklisch2017rasa,
  title={Rasa: Open source language understanding and dialogue management},
  author={Bocklisch, Tom and Faulkner, Joey and Pawlowski, Nick and Nichol, Alan},
  journal={arXiv preprint arXiv:1712.05181},
  year={2017}
}

@incollection{kuich1986linear,
  title={Linear Algebra},
  author={Kuich, Werner and Salomaa, Arto},
  booktitle={Semirings, automata, languages},
  pages={5--103},
  year={1986},
  publisher={Springer}
}

@article{schuster2018cross,
  title={Cross-lingual transfer learning for multilingual task oriented dialog},
  author={Schuster, Sebastian and Gupta, Sonal and Shah, Rushin and Lewis, Mike},
  journal={arXiv preprint arXiv:1810.13327},
  year={2018}
}

@article{viterbi1967error,
  title={Error bounds for convolutional codes and an asymptotically optimum decoding algorithm},
  author={Viterbi, Andrew},
  journal={IEEE transactions on Information Theory},
  volume={13},
  number={2},
  pages={260--269},
  year={1967},
  publisher={IEEE}
}

@article{yin2019understanding,
  title={Understanding straight-through estimator in training activation quantized neural nets},
  author={Yin, Penghang and Lyu, Jiancheng and Zhang, Shuai and Osher, Stanley and Qi, Yingyong and Xin, Jack},
  journal={arXiv preprint arXiv:1903.05662},
  year={2019}
}

@article{townsend2019extracting,
  title={Extracting relational explanations from deep neural networks: A survey from a neural-symbolic perspective},
  author={Townsend, Joseph and Chaton, Thomas and Monteiro, Jo{\~a}o M},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3456--3470},
  year={2019},
  publisher={IEEE}
}

@article{danilevsky2020survey,
  title={A survey of the state of explainable AI for natural language processing},
  author={Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj},
  journal={arXiv preprint arXiv:2010.00711},
  year={2020}
}

@inproceedings{jiang2020cold,
  title={Cold-start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks},
  author={Jiang, Chengyue and Zhao, Yinggong and Chu, Shanbo and Shen, Libin and Tu, Kewei},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={3193--3207},
  year={2020}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@article{baum1966statistical,
  title={Statistical inference for probabilistic functions of finite state Markov chains},
  author={Baum, Leonard E and Petrie, Ted},
  journal={The annals of mathematical statistics},
  volume={37},
  number={6},
  pages={1554--1563},
  year={1966},
  publisher={JSTOR}
}

@inproceedings{eisner2002parameter,
  title={Parameter estimation for probabilistic finite-state transducers},
  author={Eisner, Jason},
  booktitle={Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  pages={1--8},
  year={2002}
}

@inproceedings{konig2008g,
  title={G-REX: A versatile framework for evolutionary data mining},
  author={Konig, Rikard and Johansson, Ulf and Niklasson, Lars},
  booktitle={2008 IEEE International Conference on Data Mining Workshops},
  pages={971--974},
  year={2008},
  organization={IEEE}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:1705.07874},
  year={2017}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{tan2018distill,
  title={Distill-and-compare: Auditing black-box models using transparent model distillation},
  author={Tan, Sarah and Caruana, Rich and Hooker, Giles and Lou, Yin},
  booktitle={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={303--310},
  year={2018}
}

@article{bastani2017interpretability,
  title={Interpretability via model extraction},
  author={Bastani, Osbert and Kim, Carolyn and Bastani, Hamsa},
  journal={arXiv preprint arXiv:1706.09773},
  year={2017}
}

@article{MILLER20191,
title = {Explanation in artificial intelligence: Insights from the social sciences},
journal = {Artificial Intelligence},
volume = {267},
pages = {1-38},
year = {2019},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0004370218305988},
author = {Tim Miller},
keywords = {Explanation, Explainability, Interpretability, Explainable AI, Transparency},
abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a â€˜goodâ€™ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.}
}
